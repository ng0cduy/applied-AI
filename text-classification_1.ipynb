{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10334248,"sourceType":"datasetVersion","datasetId":6398889}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchtext.vocab import build_vocab_from_iterator\nfrom torchtext.data.utils import get_tokenizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_fscore_support, confusion_matrix\nimport pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_data(data_path):\n    data = pd.read_csv(data_path)\n    data['label'] = data['Suicide'].map({'suicide': 1, 'non-suicide': 0})\n    data = data.dropna(subset=['Tweet', 'label'])\n    # Enhanced preprocessing\n    data['Tweet'] = data['Tweet'].str.lower()\n    data['Tweet'] = data['Tweet'].str.replace(r'http\\S+|www.\\S+', '', regex=True)  # Remove URLs\n    data['Tweet'] = data['Tweet'].str.replace(r'@\\w+', '@user', regex=True)  # Standardize mentions\n    data['Tweet'] = data['Tweet'].str.replace(r'[^\\w\\s]', '', regex=True)  # Remove special characters\n    return data\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset class with proper padding\nclass TextDataset(Dataset):\n    def __init__(self, texts, labels, vocab, tokenizer):\n        self.texts = texts\n        self.labels = labels\n        self.vocab = vocab\n        self.tokenizer = tokenizer\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        tokens = self.tokenizer(self.texts.iloc[idx])\n        indices = [self.vocab[token] for token in tokens]\n        \n        # Padding/truncating\n        if len(indices) < self.max_length:\n            indices = indices + [self.vocab['<pad>']] * (self.max_length - len(indices))\n        else:\n            indices = indices[:self.max_length]\n            \n        return torch.tensor(indices, dtype=torch.long), torch.tensor(self.labels.iloc[idx], dtype=torch.long)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Enhanced model with LSTM\nclass TextClassificationModel(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, num_layers=2, dropout=0.5):\n        super(TextClassificationModel, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=1)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, \n                           batch_first=True, bidirectional=True, dropout=dropout if num_layers > 1 else 0)\n        self.dropout = nn.Dropout(dropout)\n        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # *2 for bidirectional\n        \n    def forward(self, text):\n        embedded = self.embedding(text)\n        output, (hidden, cell) = self.lstm(embedded)\n        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n        hidden = self.dropout(hidden)\n        return self.fc(hidden)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for texts, labels in dataloader:\n            texts, labels = texts.to(device), labels.to(device)\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n            \n            total_loss += loss.item()\n            preds = outputs.argmax(1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    \n    return total_loss / len(dataloader), correct / total","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, train_dataloader, val_dataloader, criterion, optimizer, \n                device, num_epochs=25, patience=3):\n    best_val_loss = float('inf')\n    patience_counter = 0\n    \n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        total_loss = 0\n        correct = 0\n        total = 0\n        \n        for texts, labels in train_dataloader:\n            texts, labels = texts.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            preds = outputs.argmax(1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n        \n        train_loss = total_loss / len(train_dataloader)\n        train_acc = correct / total\n        \n        # Validation\n        val_loss, val_acc = evaluate(model, val_dataloader, criterion, device)\n        \n        print(f'Epoch {epoch+1}/{num_epochs}:')\n        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')\n        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n        \n        # Early stopping\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            patience_counter = 0\n            torch.save(model.state_dict(), 'best_model.pt')\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print('Early stopping triggered')\n                break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EMBED_DIM = 256\nHIDDEN_DIM = 128\nBATCH_SIZE = 32\nLEARNING_RATE = 1e-4\nMAX_LENGTH = 128","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = preprocess_data('/kaggle/input/Suicide_Detection.csv')\ndata.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(\n        data['Tweet'], data['label'], test_size=0.2, random_state=42, stratify=data['label']\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = get_tokenizer('basic_english')\n# vocab = build_vocab_from_iterator(\n#         map(tokenizer, train_texts),\n#         specials=['<unk>', '<pad>'],\n#         min_freq=2)\n# vocab.set_default_index(vocab['<unk>'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = TextDataset(train_texts, train_labels, vocab, tokenizer, MAX_LENGTH)\nval_dataset = TextDataset(val_texts, val_labels, vocab, tokenizer, MAX_LENGTH)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = TextClassificationModel(\n    vocab_size=len(vocab),\n    embed_dim=EMBED_DIM,\n    hidden_dim=HIDDEN_DIM,\n    num_classes=2\n).to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n\n# Train model\ntrain_model(model, train_dataloader, val_dataloader, criterion, optimizer, device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}