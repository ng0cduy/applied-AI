{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10334248,"sourceType":"datasetVersion","datasetId":6398889}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom torchtext.legacy.data import Field, TabularDataset, BucketIterator","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/suicide-tweet/Suicide_Detection.csv\")\ndata['label'] = data['Suicide'].map({'suicide': 1, 'non-suicide': 0})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop rows with invalid or missing labels\ndata = data.dropna(subset=['Tweet', 'label'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocess tweets: lowercasing, removing special characters\ndata['Tweet'] = data['Tweet'].str.lower().str.replace(r\"[^a-zA-Z\\s]\", \"\", regex=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train-validation split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    data['Tweet'], data['label'], test_size=0.2, random_state=42\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = get_tokenizer(\"basic_english\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def yield_tokens(data_iter):\n    for text in data_iter:\n        yield tokenizer(text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vocab = build_vocab_from_iterator(yield_tokens(train_texts), specials=[\"<unk>\"])\nvocab.set_default_index(vocab[\"<unk>\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_transform = lambda x: [vocab[token] for token in tokenizer(x)]\nlabel_transform = lambda x: int(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, texts, labels, vocab, tokenizer):\n        self.texts = texts\n        self.labels = labels\n        self.vocab = vocab\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        tokens = self.tokenizer(self.texts.iloc[idx])\n        indices = self.vocab(tokens)\n        label = self.labels.iloc[idx]\n        return torch.tensor(indices, dtype=torch.long), torch.tensor(label, dtype=torch.long)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def collate_batch(batch):\n    texts, labels = zip(*batch)\n    labels = torch.tensor([int(label) for label in labels], dtype=torch.long)  # Ensure labels are integers\n    texts = [torch.tensor(text_transform(text)) for text in texts]\n    texts = nn.utils.rnn.pad_sequence(texts, batch_first=True, padding_value=vocab[\"<pad>\"])\n    return texts, labels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True, collate_fn=collate_batch)\nval_dataloader = DataLoader(val_dataset, batch_size=512, shuffle=False, collate_fn=collate_batch)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 7: Model Definition\nclass TextClassificationModel(nn.Module):\n    def __init__(self, vocab_size, embed_dim, num_classes):\n        super(TextClassificationModel, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.fc = nn.Linear(embed_dim, num_classes)\n        self.pool = nn.AdaptiveAvgPool1d(1)\n\n    def forward(self, text):\n        embedded = self.embedding(text)\n        pooled = self.pool(embedded.permute(0, 2, 1)).squeeze(-1)\n        return self.fc(pooled)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vocab_size = len(vocab)\nembed_dim = 64\nnum_classes = 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = TextClassificationModel(vocab_size, embed_dim, num_classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# num_classes = 2\n# input_dim = 768\n# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n# from torchtext.models import RobertaClassificationHead, XLMR_BASE_ENCODER\n\n# classifier_head = RobertaClassificationHead(num_classes=num_classes, input_dim=input_dim)\n# model = XLMR_BASE_ENCODER.get_model(head=classifier_head)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchtext.functional as F\nfrom torch.optim import AdamW\n\nlearning_rate = 1e-5\noptim = AdamW(model.parameters(), lr=learning_rate)\ncriteria = nn.CrossEntropyLoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train(dataloader, model, criterion, optimizer, device):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    for texts, labels in dataloader:\n        texts, labels = texts.to(device), labels.to(device)\n        optimizer.zero_grad()\n\n        outputs = model(texts)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        preds = outputs.argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n    accuracy = correct / total\n    avg_loss = total_loss / len(dataloader)\n    return avg_loss, accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(dataloader, model, criterion, device):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for texts, labels in dataloader:\n            texts, labels = texts.to(device), labels.to(device)\n\n            outputs = model(texts)\n            loss = criterion(outputs, labels)\n\n            total_loss += loss.item()\n            preds = outputs.argmax(1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n    accuracy = correct / total\n    avg_loss = total_loss / len(dataloader)\n    return avg_loss, accuracy\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n\ndef compute_metrics(dataloader, model, device):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for texts, labels in dataloader:\n            texts, labels = texts.to(device), labels.to(device)\n            outputs = model(texts)\n            preds = outputs.argmax(1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n    cm = confusion_matrix(all_labels, all_preds)\n\n    return precision, recall, f1, cm\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 25\nscheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.1)\nfor epoch in range(num_epochs):\n    train_loss, train_accuracy = train(train_dataloader, model, criteria, optim, device)\n    val_loss, val_accuracy = evaluate(val_dataloader, model, criteria, device)\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    print(f\"  Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n    print(f\"  Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n    scheduler.step()\n# Compute F1-score and Confusion Matrix after training\nprecision, recall, f1, cm = compute_metrics(val_dataloader, model, device)\nprint(\"\\nMetrics on Validation Set:\")\nprint(f\"  Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\nprint(f\"  Confusion Matrix:\\n{cm}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}